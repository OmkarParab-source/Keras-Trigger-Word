{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "from td_utils import *\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 5511\n",
    "n_freq = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ty = 1375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    X = Conv1D(filters=196, kernel_size=15, strides=4)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "\n",
    "    X = GRU(units=128, return_sequences=True)(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = GRU(units=128, return_sequences=True)(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.8)(X)\n",
    "    \n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(input_shape = (Tx, n_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat.v1.disable_v2_behavior()\n",
    "model = compat.v1.keras.models.load_model('models/tr_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword_spectrum(x):\n",
    "    x  = x.swapaxes(0,1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    predictions = model.predict(x)\n",
    "    return predictions.reshape(-1)\n",
    "\n",
    "def has_new_triggerword(predictions, chunk_duration, feed_duration, threshold=0.5):\n",
    "    predictions = predictions > threshold\n",
    "    chunk_predictions_samples = int(len(predictions) * chunk_duration / feed_duration)\n",
    "    chunk_predictions = predictions[-chunk_predictions_samples:]\n",
    "    level = chunk_predictions[0]\n",
    "    for pred in chunk_predictions:\n",
    "        if pred > level:\n",
    "            return True\n",
    "        else:\n",
    "            level = pred\n",
    "    return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_duration = 0.5\n",
    "fs = 44100\n",
    "chunk_samples = int(fs * chunk_duration)\n",
    "\n",
    "feed_duration = 10\n",
    "feed_samples = int(fs * feed_duration)\n",
    "\n",
    "assert feed_duration/chunk_duration == int(feed_duration/chunk_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(data):\n",
    "    nfft = 200\n",
    "    fs = 8000\n",
    "    noverlap = 120\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, _, _ = mlab.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, _, _ = mlab.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_spectrogram(data):\n",
    "    nfft = 200\n",
    "    fs = 8000\n",
    "    noverlap = 120\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, _, _, _ = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, _, _, _ = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_input_stream(callback):\n",
    "    stream = pyaudio.PyAudio().open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=fs,\n",
    "        input=True,\n",
    "        frames_per_buffer=chunk_samples,\n",
    "        input_device_index=0,\n",
    "        stream_callback=callback)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import sys\n",
    "import time\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "run = True\n",
    "\n",
    "silence_threshold = 50\n",
    "\n",
    "timeout = time.time() + 0.5*60\n",
    "\n",
    "data = np.zeros(feed_samples, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    if np.abs(data0).mean() < silence_threshold:\n",
    "        sys.stdout.write('-')\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "    else:\n",
    "        sys.stdout.write('.')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > feed_samples:\n",
    "        data = data[-feed_samples:]\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = get_audio_input_stream(callback)\n",
    "stream.start_stream()\n",
    "\n",
    "\n",
    "try:\n",
    "    while run:\n",
    "        data = q.get()\n",
    "        spectrum = get_spectrogram(data)\n",
    "        preds = detect_triggerword_spectrum(spectrum)\n",
    "        new_trigger = has_new_triggerword(preds, chunk_duration, feed_duration)\n",
    "        if new_trigger:\n",
    "            sys.stdout.write('1')\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False\n",
    "        \n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "silence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "data_c = None\n",
    "\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global data_c\n",
    "    data_c = np.frombuffer(in_data, dtype='int16')\n",
    "    print(np.abs(data_c).mean())\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = pyaudio.PyAudio().open(\n",
    "    format=pyaudio.paInt16,\n",
    "    channels=1,\n",
    "    rate=fs,\n",
    "    input=True,\n",
    "    frames_per_buffer=chunk_samples,\n",
    "    input_device_index=0,\n",
    "    stream_callback=callback)\n",
    "stream.start_stream()\n",
    "time.sleep(5.1)\n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06304625c64566a3879e0d3350bd7f520ecb46f2d7055ac41c7ab67b8b6f6154"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
